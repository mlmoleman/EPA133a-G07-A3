{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aa03e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "def convert_data():\n",
    "    \"\"\"\n",
    "    Converts data conform demo data files.\n",
    "    \"\"\"\n",
    "\n",
    "    # import data\n",
    "    df = pd.read_excel('../data/bridges.xlsx')\n",
    "\n",
    "    # slice data information\n",
    "    df = df[[\"road\", \"km\", \"type\", \"name\", \"length\", \"condition\", \"lat\", \"lon\", \"zone\"]]\n",
    "\n",
    "    # HANDLING MISSING VALUES\n",
    "\n",
    "    # change NaN values in name with dot i.e. '.'\n",
    "    df['name'].fillna('.', inplace=True)\n",
    "\n",
    "    # check NaN values in other columns, only length has missing values\n",
    "    df.isnull().sum(axis=0)\n",
    "\n",
    "    # assign new dataframe to missing values\n",
    "    missing = df[df.length.isnull()]\n",
    "\n",
    "    # for some missing values, missing values can be retrieved from bridges with same chainage, \n",
    "    # get length of these bridges and replace missing value with this value. \n",
    "    for index in missing.index:\n",
    "        if df.loc[index, 'km'] == df.loc[index - 1, 'km']:\n",
    "            # assign length of bridge with same chainage to variable new_length\n",
    "            new_length = df.loc[index - 1, 'length']\n",
    "            # replace missing value with new length\n",
    "            df.loc[index, 'length'] = new_length\n",
    "\n",
    "        elif df.loc[index, 'km'] == df.loc[index + 1, 'km']:\n",
    "            new_length = df.loc[index + 1, 'length']\n",
    "            df.loc[index, 'length'] = new_length\n",
    "\n",
    "    # for the left-over missing values, replace length with average length of bridges for specific road\n",
    "    for index in missing.index:\n",
    "        road_name = df.loc[index, 'road']\n",
    "        road_subset = df[df['road'] == road_name]\n",
    "        average_length = road_subset.loc[:, 'length'].mean()\n",
    "        df.loc[index, 'length'] = average_length\n",
    "\n",
    "    # HANDLING DUPLICATES\n",
    "\n",
    "    # change type of column first\n",
    "    df['name'] = df['name'].astype(str)\n",
    "\n",
    "    # replace modifications of right/left in bridge names\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace(')', ''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('RIGHT', 'R'))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('LEFT', 'L'))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('Right', 'R'))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('Left', 'L'))\n",
    "\n",
    "    # strip the trailing whitespaces \n",
    "    df['name'] = df['name'].apply(lambda x: x.strip())\n",
    "\n",
    "    # change condition from letters to numbers in order to compare them\n",
    "    df['conditionNum'] = 0\n",
    "    df.loc[df['condition'] == 'A', 'conditionNum'] = 1\n",
    "    df.loc[df['condition'] == 'B', 'conditionNum'] = 2\n",
    "    df.loc[df['condition'] == 'C', 'conditionNum'] = 3\n",
    "    df.loc[df['condition'] == 'D', 'conditionNum'] = 4\n",
    "\n",
    "    for road in df.road:\n",
    "        # define dataframe for duplicates\n",
    "        road_subset = df[df['road'] == road]\n",
    "        # subset based on latitude and longitude\n",
    "        duplicates = road_subset[road_subset.duplicated(subset=['lat', 'lon'])]\n",
    "        # sort by chainage\n",
    "        duplicates.sort_values(by=['km'])\n",
    "\n",
    "        # initialize a list for indexes to remove after running for-loop\n",
    "        remove_index = []\n",
    "\n",
    "        for index in duplicates.index:\n",
    "            # retrieve latitude and longitude\n",
    "            latitude = df.loc[index, 'lat']\n",
    "            longitude = df.loc[index, 'lon']\n",
    "\n",
    "            # define a subset of duplicates based on the latitude and longitude\n",
    "            subset = df.loc[((df['lat'] == latitude) & (df['lon'] == longitude))]\n",
    "\n",
    "            # define lists for bridges with left, right, or neither in their name\n",
    "            contains_left = []\n",
    "            contains_right = []\n",
    "            contains_none = []\n",
    "\n",
    "            for index in subset.index:\n",
    "                # for every row in subset, retrieve condition and assign to set\n",
    "                condition = subset.loc[index, 'conditionNum']\n",
    "                # define the set with both index and condition\n",
    "                condition_set = (index, condition)\n",
    "\n",
    "                # retrieve name and whether L or R in name\n",
    "                name = subset.loc[index, 'name']\n",
    "                last_letter = name[-1:]\n",
    "                # check whether last letter is R, L, or something else\n",
    "                if last_letter == 'R':\n",
    "                    contains_right.append(condition_set)\n",
    "\n",
    "                elif last_letter == 'L':\n",
    "                    contains_left.append(condition_set)\n",
    "\n",
    "                else:\n",
    "                    contains_none.append(condition_set)\n",
    "\n",
    "                    # when no left and right in name, but other letters\n",
    "            if len(contains_left) == 0 and len(contains_right) == 0 and len(contains_none) > 0:\n",
    "                # check whether conditions of bridges are equal\n",
    "                if contains_none[0][1] == contains_none[1][1]:\n",
    "                    # if so, pick random index and append to list\n",
    "                    random_none = random.choice(contains_none)\n",
    "                    remove_index.append(random_none[0])\n",
    "\n",
    "                # if condition of one is greater than other, remove the highest one\n",
    "                # better be safe than sorry\n",
    "                elif contains_none[0][1] < contains_none[1][1]:\n",
    "                    remove_index.append(contains_none[0][0])\n",
    "\n",
    "                elif contains_none[0][1] > contains_none[1][1]:\n",
    "                    remove_index.append(contains_none[1][0])\n",
    "\n",
    "            # capitalized one is often an updated version, we assume. Hence, remove the left and right\n",
    "            if len(contains_left) == 1 and len(contains_right) == 1 and len(contains_none) == 1:\n",
    "                for element in contains_left:\n",
    "                    remove_index.append(element[0])\n",
    "                for element in contains_right:\n",
    "                    remove_index.append(element[0])\n",
    "\n",
    "            # if two times left\n",
    "            if len(contains_left) == 2:\n",
    "                # check whether conditions are equal\n",
    "                if contains_left[0][1] == contains_left[1][1]:\n",
    "                    # then randomly pick one\n",
    "                    random_left = random.choice(contains_left)\n",
    "                    remove_index.append(random_left[0])\n",
    "\n",
    "                # else check which condition is better, remove that one\n",
    "                elif contains_left[0][1] < contains_left[1][1]:\n",
    "                    remove_index.append(contains_left[0][0])\n",
    "\n",
    "                elif contains_left[0][1] > contains_left[1][1]:\n",
    "                    remove_index.append(contains_left[1][0])\n",
    "\n",
    "            # same structure as with left, now for right\n",
    "            if len(contains_right) == 2:\n",
    "                if contains_right[0][1] == contains_right[1][1]:\n",
    "                    random_left = random.choice(contains_right)\n",
    "                    remove_index.append(random_left[0])\n",
    "\n",
    "                elif contains_right[0][1] < contains_right[1][1]:\n",
    "                    remove_index.append(contains_right[0][0])\n",
    "\n",
    "                elif contains_right[0][1] > contains_right[1][1]:\n",
    "                    remove_index.append(contains_right[1][0])\n",
    "\n",
    "            # if left and capital, remove left one\n",
    "            if len(contains_left) == 1 and len(contains_none) == 1:\n",
    "                for element in contains_left:\n",
    "                    remove_index.append(element[0])\n",
    "\n",
    "            # if right and capital, remove right one\n",
    "            if len(contains_right) == 1 and len(contains_none) == 1:\n",
    "                for element in contains_right:\n",
    "                    remove_index.append(element[0])\n",
    "\n",
    "            # if both right and left, keep both \n",
    "            if len(contains_right) == 1 and len(contains_left) == 1 and len(contains_none) == 0:\n",
    "                continue\n",
    "\n",
    "        # only retrieve unique indexes in list, otherwise we remove all\n",
    "        used = set()\n",
    "        unique_indexes = [x for x in remove_index if x not in used and (used.add(x) or True)]\n",
    "\n",
    "        # remove all the indexes in removing list\n",
    "        for element in unique_indexes:\n",
    "            df = df.drop(index=element)\n",
    "\n",
    "    # FORMAT DATAFRAME CONFORM DEMO FILES\n",
    "\n",
    "    # add model type\n",
    "    df['model_type'] = 'bridge'\n",
    "\n",
    "    # sort values based on km and road name\n",
    "    df = df.sort_values(by=['road', 'km'])\n",
    "\n",
    "    # reset index\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # drop unnecessary columns\n",
    "    df = df.drop(\"conditionNum\", axis='columns')\n",
    "    df = df.drop(\"index\", axis='columns')\n",
    "    df = df.drop(\"zone\", axis='columns')\n",
    "    \n",
    "    # ADD SOURCES AND SINKS\n",
    "    \n",
    "    # import roads to get source and sink\n",
    "    df_roads = pd.read_csv('../data/roads.csv')\n",
    "\n",
    "    # all rows with chainage equal to zero are sources\n",
    "    sources = df_roads[df_roads.chainage == 0.000]\n",
    "\n",
    "    # modify sources dataframe conform current dataset\n",
    "    sources = sources.copy()\n",
    "    sources.rename({'chainage': 'km'}, axis=1, inplace=True)\n",
    "    sources['type'] = 'source'\n",
    "    sources['model_type'] = 'source'\n",
    "    sources['name'] = 'source'\n",
    "    sources['condition'] = None\n",
    "    sources['length'] = 0\n",
    "\n",
    "    # drop unnecessary columns\n",
    "    sources = sources.drop(\"lrp\", axis='columns')\n",
    "    sources = sources.drop(\"gap\", axis='columns')\n",
    "\n",
    "    # reset index\n",
    "    sources  = sources.reset_index(drop = True)\n",
    "\n",
    "    # add sources to dataframe\n",
    "    df = pd.concat([df, sources])\n",
    "\n",
    "    # initialize list with indexes which are sinks\n",
    "    sinks_indexes = []\n",
    "    # sort roads dataframe based on road name and chainage\n",
    "    df_roads = df_roads.sort_values(by=['road', 'chainage'])\n",
    "    # reset index\n",
    "    df_roads = df_roads.reset_index(drop = True)\n",
    "    # retrieve all unique roads in roads column of dataframe\n",
    "    roads = df_roads['road'].unique().tolist()\n",
    "\n",
    "    # for each road\n",
    "    for road in roads: \n",
    "        # subset this road\n",
    "        road_subset = df_roads[df_roads['road'] == road]\n",
    "        # retrieve index of last row\n",
    "        road_last_index = road_subset.index[-1]\n",
    "        # add row to indexes list\n",
    "        sinks_indexes.append(road_last_index)\n",
    "        \n",
    "    # get all rows with index in sinks_indexes and assign as sink in dataframe\n",
    "    sinks = df_roads.iloc[sinks_indexes]\n",
    "    \n",
    "    # modify sinks dataframe conform dataset\n",
    "    sinks = sinks.copy()\n",
    "    sinks.rename({'chainage': 'km'}, axis=1, inplace=True)\n",
    "    sinks['type'] = 'sink'\n",
    "    sinks['model_type'] = 'sink'\n",
    "    sinks['name'] = 'sink'\n",
    "    sinks['condition'] = None\n",
    "    sinks['length'] = 0\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    sinks = sinks.drop(\"lrp\", axis='columns')\n",
    "    sinks = sinks.drop(\"gap\", axis='columns')\n",
    "    \n",
    "    # add sources to dataset\n",
    "    df = pd.concat([df, sinks])\n",
    "    \n",
    "    # sort values based on km and road name\n",
    "    df = df.sort_values(by=['road', 'km'])\n",
    "\n",
    "    # reset index\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # convert dataframe to csv\n",
    "    df.to_csv('../data/bridges_cleaned_without_sourcesink.csv')\n",
    "\n",
    "    \n",
    "# call function\n",
    "df = convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a75cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
